{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17097546483049236017\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1412474060\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1514262421367066692\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#to see current gpu is available or not\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use keras on gpu\n",
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (60000, 28, 28, 1)\n",
      "Shape of features: (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the training Data\n",
    "fashion_train = pd.read_csv('D:\\\\fashion-mnist_train.csv')\n",
    "f_train = fashion_train.astype(\"float32\")/255\n",
    "\n",
    "#select features for training\n",
    "X_train = f_train.iloc[:,1:]\n",
    "\n",
    "#convert into array\n",
    "X_train = np.array(X_train, dtype = 'float32')\n",
    "\n",
    "#Reshape\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "\n",
    "#Shape of features\n",
    "print('Shape of features:',X_train.shape)\n",
    "\n",
    "#target for training\n",
    "Y_train = fashion_train.iloc[:,0]\n",
    "\n",
    "#convert into array\n",
    "Y_train = np.array(Y_train, dtype = 'float32')\n",
    "\n",
    "#Shape of target\n",
    "print('Shape of features:',Y_train.shape)\n",
    "\n",
    "#define load_data\n",
    "def load_data():\n",
    "    X_train\n",
    "    Y_train\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ce84e3408>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#View the image how it looks\n",
    "image = np.reshape(fashion_train[fashion_train.columns[1:]].iloc[5].values/255, (28,28))\n",
    "plt.figure()\n",
    "plt.title(\"labeled class {}\".format(fashion_train[\"label\"].iloc[5]))\n",
    "plt.imshow(image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras models and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "#                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "#                                   tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    "#  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#  tf.keras.layers.Flatten(),\n",
    "#  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#  tf.keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Model Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    "#  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#  tf.keras.layers.Flatten(),\n",
    "#  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#  tf.keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st convolutional layer\n",
    "#fashion_model3 = Sequential()\n",
    "#fashion_model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "#fashion_model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#fashion_model3.add(Dropout(0.30))\n",
    "\n",
    "#2nd convolutional layer\n",
    "#fashion_model3.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))\n",
    "#fashion_model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#fashion_model3.add(Dropout(0.30))\n",
    "\n",
    "#flatten layer\n",
    "#fashion_model3.add(Flatten())\n",
    "\n",
    "#dense layers\n",
    "#fashion_model3.add(Dense(512, activation='relu'))\n",
    "#fashion_model3.add(Dropout(0.30))\n",
    "#fashion_model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Model Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDING MORE CONVOLUTIONAL LAYERS AND DROPOUT LAYER\n",
    "#Dropout is the method used to reduce overfitting. \n",
    "#toforces the model to learn multiple independent representations of the same data by randomly disabling neurons in the learning phase.\n",
    "def fashion_model():\n",
    "\n",
    "#1st convolutional layer\n",
    "    fashion_model = Sequential()\n",
    "    fashion_model.add(Conv2D(32, kernel_size=(3, 3),padding = 'same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    fashion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    fashion_model.add(Dropout(0.30))\n",
    "\n",
    "#2nd convolutional layer\n",
    "    fashion_model.add(Conv2D(64, kernel_size=(3, 3), padding = 'same', activation='relu'))\n",
    "    fashion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    fashion_model.add(Dropout(0.30))\n",
    "\n",
    "#flatten layer\n",
    "    fashion_model.add(Flatten())\n",
    "\n",
    "#dense layers\n",
    "    fashion_model.add(Dense(128, activation='relu'))\n",
    "    fashion_model.add(Dropout(0.30))\n",
    "    fashion_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#model complie\n",
    "    fashion_model.compile(optimizer = keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])     \n",
    "    return fashion_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model save\n",
    "def final_model():\n",
    "    # define model\n",
    "    model = fashion_model()\n",
    "    #load data\n",
    "    X_train, Y_train = load_data()\n",
    "    model.fit(X_train, Y_train, epochs=100)\n",
    "    model.save('fashion_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Keval\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Keval\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.5147 - accuracy: 0.8123\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.3571 - accuracy: 0.8712\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.3154 - accuracy: 0.8849\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.2910 - accuracy: 0.8942\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.2738 - accuracy: 0.8989\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2577 - accuracy: 0.9042\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2464 - accuracy: 0.9097\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.2378 - accuracy: 0.9124\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.2303 - accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2255 - accuracy: 0.9158\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.2220 - accuracy: 0.9165\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2163 - accuracy: 0.9201\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2112 - accuracy: 0.9191\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2067 - accuracy: 0.9222\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.2028 - accuracy: 0.9234\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1980 - accuracy: 0.9261\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1980 - accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1917 - accuracy: 0.9289\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1909 - accuracy: 0.9287\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1896 - accuracy: 0.9285\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1847 - accuracy: 0.9303\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1830 - accuracy: 0.9311\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1806 - accuracy: 0.9308\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1795 - accuracy: 0.9311\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1756 - accuracy: 0.9328\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1743 - accuracy: 0.9344\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1740 - accuracy: 0.9352\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1734 - accuracy: 0.9338\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1714 - accuracy: 0.9360\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1684 - accuracy: 0.9364\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1679 - accuracy: 0.9364\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1655 - accuracy: 0.9367\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1660 - accuracy: 0.9383\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1621 - accuracy: 0.9372\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1634 - accuracy: 0.9372\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1612 - accuracy: 0.9391\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1587 - accuracy: 0.9392\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1597 - accuracy: 0.9401\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1588 - accuracy: 0.9391\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1584 - accuracy: 0.9402\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1583 - accuracy: 0.9404\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.1558 - accuracy: 0.9404\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1530 - accuracy: 0.9421\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1557 - accuracy: 0.9416\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1506 - accuracy: 0.9416\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1530 - accuracy: 0.9429\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1544 - accuracy: 0.9422\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1509 - accuracy: 0.9432\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1485 - accuracy: 0.9443\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1504 - accuracy: 0.9434\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1492 - accuracy: 0.9438\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1458 - accuracy: 0.9447\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1449 - accuracy: 0.9459\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1473 - accuracy: 0.9435\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1467 - accuracy: 0.9451\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1491 - accuracy: 0.9444\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1452 - accuracy: 0.9458\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1435 - accuracy: 0.9461\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1462 - accuracy: 0.9459\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.1438 - accuracy: 0.9471\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1427 - accuracy: 0.9459\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.1426 - accuracy: 0.9464\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.1458 - accuracy: 0.9451\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1384 - accuracy: 0.9477\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1432 - accuracy: 0.9458\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1386 - accuracy: 0.9478\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.1386 - accuracy: 0.9480\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1399 - accuracy: 0.9467\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1405 - accuracy: 0.9469\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1395 - accuracy: 0.9480\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1373 - accuracy: 0.9481\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1395 - accuracy: 0.9479\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1395 - accuracy: 0.9486\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1356 - accuracy: 0.9487\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1377 - accuracy: 0.9485\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1347 - accuracy: 0.9495\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1365 - accuracy: 0.9481\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1389 - accuracy: 0.9475\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1347 - accuracy: 0.9482\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1364 - accuracy: 0.9492\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1358 - accuracy: 0.9489\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1307 - accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1342 - accuracy: 0.9501\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1335 - accuracy: 0.9502\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1344 - accuracy: 0.9498\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1338 - accuracy: 0.9491\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1293 - accuracy: 0.9515\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1323 - accuracy: 0.9512\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.1300 - accuracy: 0.9512\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1342 - accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1351 - accuracy: 0.9498\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.1331 - accuracy: 0.9506\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.1286 - accuracy: 0.9512\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.95 - 12s 203us/step - loss: 0.1315 - accuracy: 0.9509\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1338 - accuracy: 0.9499\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1283 - accuracy: 0.9518\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.1302 - accuracy: 0.9518\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1334 - accuracy: 0.9493\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1310 - accuracy: 0.9512\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1289 - accuracy: 0.9530\n"
     ]
    }
   ],
   "source": [
    "final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (10000, 28, 28, 1)\n",
      "Shape of target: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "fashion_test = pd.read_csv('D:\\\\fashion-mnist_test.csv')\n",
    "\n",
    "#convert into array\n",
    "f_test = fashion_test.astype(\"float32\")/255\n",
    "\n",
    "#features for testing\n",
    "X_test = f_test.iloc[:,1:]\n",
    "\n",
    "#convert into array\n",
    "X_test = np.array(X_test, dtype = 'float32')\n",
    "\n",
    "#Reshape\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "#Shape of test Data\n",
    "print('Shape of features:',X_test.shape)\n",
    "\n",
    "#target for testing\n",
    "Y_test = fashion_test.iloc[:,0]\n",
    "\n",
    "#convert into array\n",
    "Y_test = np.array(Y_test, dtype = 'float32')\n",
    "\n",
    "#Shape of target\n",
    "print('Shape of target:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Keval\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keval\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Keval\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "10000/10000 [==============================] - 4s 382us/step\n",
      "Test loss 0.20110615355269984\n",
      "Test accuracy 0.9340000152587891\n"
     ]
    }
   ],
   "source": [
    "#eveluate model for test accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test loss', test_loss)\n",
    "print('Test accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import_Resize_Reshape_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages for importing image\n",
    "from scipy.misc import imread\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For inporting multiple images with transformation\n",
    "folders = glob.glob('D:\\\\Semester 3\\\\Machine Learning 2\\\\resized\\\\')\n",
    "imagenames__list = []\n",
    "for folder in folders:\n",
    "    for f in glob.glob(folder+'/*'):\n",
    "       imagenames__list.append(f)\n",
    "\n",
    "import_img = []\n",
    "for image in imagenames__list:\n",
    "    import_img.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE)) #import image directly in grayscale\n",
    "\n",
    "resize_img = []\n",
    "for new in import_img:\n",
    "    resize_img.append(cv2.resize(new, (28,28))) #resize image\n",
    "\n",
    "reshape_img = []\n",
    "for new_img in resize_img:\n",
    "    reshape_img.append(new_img.reshape(1,28,28,1)) #reshape image\n",
    " \n",
    "final_img = []\n",
    "for f_img in reshape_img:\n",
    "    final_img.append(f_img.astype(\"float32\")/255) #devide by 255 for normization   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c2eb829c8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see the image how ot look after transformation\n",
    "plt.imshow(resize_img[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[1]\n",
      "[3]\n",
      "[3]\n",
      "[5]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[6]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "#create list of 0-30\n",
    "abc = np.array(list(range(0,30)))\n",
    "#predicting all the images\n",
    "for i in abc:\n",
    "    model.predict_classes(final_img[i])\n",
    "\n",
    "    print(model.predict_classes(final_img[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Class\n",
    "# 9, 9, 9, 8, 8, 8, 4, 4, 4, 3, 3, 3, 2, 2, 2, 5, 5, 5, 6, 6, 6, 7, 7, 7, 0, 0, 0, 1, 1, 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}